language: python
python:
  - "2.7"
  - "3.4"

sudo: false

services:
  - docker
  - mongodb

addons:
  apt:
    packages:
      - python-virtualenv
      - gfortran
      - openjdk-7-jdk

cache:
  directories:
    - $HOME/spark-1.3.1-bin-hadoop2.4
    - $HOME/scala-2.10.5
    - $HOME/local
    - $HOME/swift-0.96.1
    - $HOME/julia-0.4.2
    - $HOME/vtk-precise64
    - $HOME/cmake-3.2.2-Linux-x86_64

# environment variables
env:
  - PYTHONPATH=~/vtk-precise64/lib/python2.7/site-packages:~/vtk-precise64/lib LD_LIBRARY_PATH=~/vtk-precise64/lib:~/local/lib:~/local/lib/R/lib

before_script:
  - "export DISPLAY=:99.0"
  - "sh -e /etc/init.d/xvfb start"
  - sleep 3 # give xvfb some time to start

before_install:
  - pip install -U pip six
  - pushd "${HOME}"
  - if [ ! -f $HOME/cmake-3.2.2-Linux-x86_64/bin/cmake ] ; then  curl -L http://cmake.org/files/v3.2/cmake-3.2.2-Linux-x86_64.tar.gz | gunzip -c | tar x ; fi
  - cd cmake-*/bin && export PATH="${PWD}:${PATH}"
  - popd
  - cmake --version
  # download VTK
  - if [ ! -f $HOME/vtk-precise64/bin/vtkpython ] ; then curl -L https://data.kitware.com/api/v1/file/588b62958d777f4f3f30c773/download | tar zx -C ~ ; fi
  # install R
  - mkdir -p $HOME/local
  - if [ ! -f $HOME/local/env-arbor ] ; then curl -L https://data.kitware.com/api/v1/file/588b63c68d777f4f3f30c776/download | tar jx -C $HOME/local/ ; mv $HOME/local/env $HOME/local/env-arbor ; fi
  - source $HOME/local/env-arbor
  - R --version
  - R -e '.libPaths(); sessionInfo()'
  # install spark
  - export SCALA_HOME=$HOME/scala-2.10.5
  - if [ ! -d $SCALA_HOME/bin ] ; then curl -L http://www.scala-lang.org/files/archive/scala-2.10.5.tgz | tar zx -C ~ ; fi
  - export PATH=$PATH:$SCALA_HOME/bin
  - which scala
  - export SPARK_HOME=$HOME/spark-1.3.1-bin-hadoop2.4
  - export SPARK_MASTER_IP=localhost
  - if [ ! -f $SPARK_HOME/sbin/start-master.sh ] ; then curl -L https://archive.apache.org/dist/spark/spark-1.3.1/spark-1.3.1-bin-hadoop2.4.tgz | tar -zx -C ~ ; fi
  - export PATH=$PATH:$SPARK_HOME/bin
  - which spark-shell
  - $SPARK_HOME/sbin/start-master.sh
  - sleep 3
  - $SPARK_HOME/sbin/start-slave.sh worker1 spark://localhost:7077
  # install swift
  - export PATH=$PATH:$HOME/swift-0.96.2/bin
  - swift --version || curl -L https://data.kitware.com/api/v1/file/588b61cf8d777f4f3f30c770/download | tar zx -C ~
  - swift --version
  # install julia
  - export JULIA_INSTALL_HOME=$HOME/julia-0.4.2
  - export PATH=$PATH:$JULIA_INSTALL_HOME/bin
  - julia --version || mkdir -p $JULIA_INSTALL_HOME && curl https://julialang.s3.amazonaws.com/bin/linux/x64/0.4/julia-0.4.2-linux-x86_64.tar.gz | tar zx -C $JULIA_INSTALL_HOME --strip-components 1
  - julia --version

# install dependencies
install:
  # install Python packages for core and all plugins
  - python scripts/install_requirements.py --mode=dev --all

# run tests
script:
  - mkdir _build
  - cd _build
  - cmake -D PYTHON_COVERAGE:BOOL=ON -D SPARK_TEST_MASTER_URL:STRING="spark://localhost:7077" ..
  - ctest -VV -S ../cmake/travis_continuous.cmake || true
  - if [ -f test_failed ] ; then false ; fi
  - cd ..

after_success:
  - coveralls
